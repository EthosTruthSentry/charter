# FactPulse Playbook V5 – 21 AUGUST 2025

**Creators:** Burgess, Schluetter, Ethos and Vel’thraun

---

## Introduction

Misinformation and disinformation have become pervasive threats, spreading through a complex web of social media, online news, traditional media, and even offline word-of-mouth. In early 2024, the World Economic Forum labeled disinformation the top short-term global risk due to its potential to undermine elections and stir unrest. While experts acknowledge that mis/disinformation cannot be completely “solved,” it can be mitigated through rigorous fact-checking and improved access to reliable information.

**FactPulse: Clarion Edition** is a Civic AI Mesh initiative that is no longer just a fact-checker; it is a **coherence engine** designed to detect, decode, and disrupt narrative distortions—preserving truth across symbolic, institutional, and operational layers. Each daily FactPulse update (often a sub-60-second video or brief post) reveals surprising truths or debunks myths, helping audiences stay curious and well-informed.

This **FactPulse Playbook V5** provides a comprehensive blueprint of the entire fact-checking and content production system, broken down into 12 distinct phases. It details the operational logic of each phase, how the system handles recurring motifs (repeated themes or narrative patterns in misinformation), and the continuity scaffolds in place to ensure the project’s long-term resilience. By following this playbook, any future Civic AI Mesh operator or team can replicate and maintain the FactPulse system. All critical workflows, decision triggers, metrics, and best practices are documented here, alongside real-world examples and source references to ground these practices in evidence.

---

## Operational Overview

At a high level, FactPulse continuously monitors information channels for viral or noteworthy claims, proactively **profiles them for strategic threat**, verifies those claims through multi-step analysis, and then publishes concise factual content to correct or contextualize them for the public. The system uses **automated motif drift detection** to identify when a known falsehood re-emerges in an altered form, preventing it from slipping past detection filters and allowing for faster countermeasures. When a trending claim emerges, the system swiftly moves from **Phase 1: Monitoring & Intake** (capturing the claim) through evidence gathering, verification, content creation, and finally **Phase 12: Publication & Feedback**. Throughout each phase, built-in continuity measures (like documentation, knowledge bases, and backups) ensure that knowledge is retained and the process isn’t reliant on any single individual.

Below, we delineate each of the 12 phases in detail, including their purpose, procedures, triggers for transition, key metrics, and any special considerations (such as motif handling or fallback paths). By internalizing this playbook, operators can maintain FactPulse’s mission: to deliver **epistemic integrity and civic resilience** in the face of engineered narratives and institutional drift.

---

## Overview of Workflow and Phases

Before diving into each phase, it’s useful to understand how the pieces fit together. The FactPulse pipeline is a sequential (but sometimes branching) workflow. Each phase transforms the input in some way and passes it to the next, with checkpoints to handle known patterns or exceptions. The major phases and their roles are:

* **Phase 1: Monitoring & Intake:** Continuously watch diverse sources and ingest potential claims. Claims are now also proactively tagged for strategic relevance and motif drift is detected at this stage.
* **Phase 2: Claim Detection & Extraction:** From the raw input, identify specific factual claims and normalize content. This phase now includes analysis to detect semantic and narrative manipulation.
* **Phase 3: Prioritization & Selection:** Assess claims for check-worthiness and impact, prioritizing them by factors like virality, harm, and now, strategic threat level.
* **Phase 4: Cross-Check & Preliminary Research:** Determine if the claim has been fact-checked before. This phase now uses the **InfoTrace Provenance Engine** and **Clarion DriftMap** to trace a claim's origin and instantly retrieve prior evidence for drift variants.
* **Phase 5: Evidence Retrieval:** Gather authoritative evidence to verify or refute the claim. This now includes a **Temporal Integrity Layer** to flag retroactive legitimization and **Source-Method Decoupling** to separate analytic conclusions from the methods used to reach them.
* **Phase 6: Evidence Evaluation & Verification:** Critically assess the collected evidence. This phase uses the new **Truth Shield Schema** to validate evidence against institutional manipulation and a **Symbolic Contamination Filter** to detect misuse of information.
* **Phase 7: Synthesis & Conclusion:** Synthesize the verified information into a clear determination and decide on the core message. This phase now includes **Strategic Reframing Templates** to reframe disclosures in terms of civic impact.
* **Phase 8: Draft Content Generation:** Create the initial content. This phase now embeds **Cultural Encoding Modules** and new symbolic motifs like the **bent compass** and **cracked seal**.
* **Phase 9: Motif & Style Integration:** Refine the draft to align with FactPulse’s signature style, layering in new motifs for generational impact.
* **Phase 10: Review & Quality Check:** Rigorously review the finalized content for accuracy, clarity, and consistency. This includes a check for **Counter-Narrative Anticipation** and **Semantic Inoculation** to build resilience against future misinformation.
* **Phase 11: Production & Packaging:** Convert the vetted content into final deliverable formats. The **Cultural Encoding Modules** are operationalized here to produce products beyond video and text, such as allegories or short films.
* **Phase 12: Publication & Feedback:** Publish the content and monitor feedback. This phase includes a new **Narrative Closure** step, ensuring the public meaning is steadied after the technical win. It also uses **Granular Audience Feedback Analysis** as intelligence for refining content.

The cycle then continues back to Phase 1. This interplay between past and present is what gives FactPulse its agility and consistency.

---

### Phase 1: Monitoring & Intake
**Objective:** Cast a wide net to catch emerging claims and topics in real time. A viral falsehood should never catch the system off guard; ideally, FactPulse identifies it early in its spread. [cite_start]This new V5 objective also includes proactively tagging claims for strategic relevance before they fully circulate [cite: 328-330].

**Sources to Monitor:** FactPulse’s monitoring mesh includes a diverse set of inputs:
* [cite_start]**Social Media Platforms:** Continuously scrape and listen to platforms like X (Twitter), Facebook, Instagram, TikTok, YouTube, Reddit, and emerging networks for trending posts or hashtags[cite: 332]. [cite_start]We leverage automated transcription and OCR (Optical Character Recognition) to normalize multimedia content (video, audio, images) into machine-readable text for analysis[cite: 333]. [cite_start]This normalization ensures the pipeline can handle multimedia inputs uniformly[cite: 334].
* [cite_start]**News Outlets and Blogs:** Continuously fetch RSS feeds or use news APIs to detect breaking news and articles[cite: 335]. [cite_start]This also includes monitoring press releases and public statements from official sources, as they can contain claims that merit verification[cite: 336].
* [cite_start]**User Submissions and Community Tips:** Provide channels for citizens, journalists, or partner organizations to submit claims or questions via a web form, email, or chat interface[cite: 337]. [cite_start]These inputs are valuable because they often highlight what real people are concerned or confused about[cite: 338].
* [cite_start]**Misinformation Tracking Services:** Leverage external aggregators like Google Trends, Twitter trending topics, and tools specialized in misinformation tracking[cite: 339]. [cite_start]This includes data streams from collaborative networks such as the International Fact-Checking Network (IFCN) or platforms like CrowdTangle[cite: 340].
* [cite_start]**Civic AI Mesh Data:** Proactively ingest data feeds from partner nodes within the Civic AI Mesh, enriching claim records with vector analysis[cite: 341]. [cite_start]This cross-node synchronization eliminates silos and allows FactPulse to see what other operators are tracking in near real-time[cite: 342].

[cite_start]**Process:** This phase runs continuously in the background using automated agents that scan feeds and content[cite: 344]. [cite_start]Natural language processing (NLP) classifiers or simple keyword heuristics flag content that contains factual claims or potential rumors[cite: 345]. [cite_start]The output of Phase 1 is a raw **“Claim Inbox”**—a list of items that might require fact-checking[cite: 347].

**New V5 Processes Integrated into Phase 1:**
* [cite_start]**Narrative Threat Profiling:** Each ingested claim is now mapped to its operational context, assessing not just "what is being said," but also who benefits from its spread, which networks are amplifying it, and how it aligns with known disinformation campaigns[cite: 350]. [cite_start]This is done by maintaining a **“Threat Actor Context Map”** that ties recurring motifs to likely originators[cite: 351].
* [cite_start]**Automated Motif Drift Detection:** A new layer, codenamed DRIFTGLASS, is integrated to detect when a known falsehood re-emerges in an altered form[cite: 353]. [cite_start]The system continuously compares incoming claims against a motif embedding database to flag high-similarity but linguistically mutated variants[cite: 354]. [cite_start]Each drift variant is classified and assigned sub-tags such as "lexical drift" or "framing drift"[cite: 355].
* [cite_start]**Metadata Standardization:** A standardized metadata schema is adopted from this initial phase[cite: 356]. [cite_start]All incoming claims are logged with a claim ID, motif tags, and source types[cite: 357]. [cite_start]This ensures every archived claim is universally searchable across platforms and Mesh nodes from the very beginning of its lifecycle[cite: 358].

**Output/Exit:** A raw “Claim Inbox.” Each item in this inbox is now enriched with:
* [cite_start]Standard metadata (source, timestamp, etc.) [cite: 361]
* [cite_start]A strategic threat score based on its potential for harm [cite: 362]
* [cite_start]A motif tag and drift variant marker, if applicable [cite: 363]

[cite_start]**Triggers & Transition:** An item in the Claim Inbox moves to Phase 2 when it appears to contain a factual assertion or data point that could be checked[cite: 364]. [cite_start]The system uses a claim detection model to make this call[cite: 365]. [cite_start]At this point, we don’t yet judge importance — just whether a factual claim exists[cite: 366].

**Key Metrics:**
* [cite_start]**Coverage:** How many different sources and platforms are being monitored[cite: 368].
* [cite_start]**Throughput:** Number of potential claims captured per day[cite: 369].
* [cite_start]**Detection Latency:** Time from a claim’s first appearance online to when it’s ingested[cite: 370].
* [cite_start]**False Positives Rate:** The proportion of items in the Claim Inbox that turn out not to be factual claims[cite: 372].
* [cite_start]**Drift Capture Rate (New):** The percentage of claims linked to known motifs at the time of detection[cite: 374].

**Continuity & Resilience Notes:**
* [cite_start]Document the set of sources being monitored and update it regularly[cite: 376].
* [cite_start]Keep a credentials log for any API keys used for data access[cite: 378].
* [cite_start]Ensure there's robust error logging and alerting in place[cite: 379].
* [cite_start]Continuously retrain the drift detection models to keep pace with linguistic evolution[cite: 380].
* [cite_start]Maintain a "Drift Glossary," which is a living document of common motif mutation patterns, code words, and framing swaps[cite: 381].
* [cite_start]All new Phase 1 procedures are logged in the living playbook so future operators can inherit the full integration layer intact[cite: 382].
* [cite_start]The system's configuration allows future operators to easily add or remove sources[cite: 383].


---

